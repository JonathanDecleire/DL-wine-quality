{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "#import jovian\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "df = pd.read_csv('wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>4893</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>4894</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>4895</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>4896</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>4897</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0         0            7.4              0.70         0.00             1.9   \n",
       "1         1            7.8              0.88         0.00             2.6   \n",
       "2         2            7.8              0.76         0.04             2.3   \n",
       "3         3           11.2              0.28         0.56             1.9   \n",
       "4         4            7.4              0.70         0.00             1.9   \n",
       "...     ...            ...               ...          ...             ...   \n",
       "6492   4893            6.2              0.21         0.29             1.6   \n",
       "6493   4894            6.6              0.32         0.36             8.0   \n",
       "6494   4895            6.5              0.24         0.19             1.2   \n",
       "6495   4896            5.5              0.29         0.30             1.1   \n",
       "6496   4897            6.0              0.21         0.38             0.8   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0         0.076                 11.0                  34.0  0.99780  3.51   \n",
       "1         0.098                 25.0                  67.0  0.99680  3.20   \n",
       "2         0.092                 15.0                  54.0  0.99700  3.26   \n",
       "3         0.075                 17.0                  60.0  0.99800  3.16   \n",
       "4         0.076                 11.0                  34.0  0.99780  3.51   \n",
       "...         ...                  ...                   ...      ...   ...   \n",
       "6492      0.039                 24.0                  92.0  0.99114  3.27   \n",
       "6493      0.047                 57.0                 168.0  0.99490  3.15   \n",
       "6494      0.041                 30.0                 111.0  0.99254  2.99   \n",
       "6495      0.022                 20.0                 110.0  0.98869  3.34   \n",
       "6496      0.020                 22.0                  98.0  0.98941  3.26   \n",
       "\n",
       "      sulphates  alcohol  quality  \n",
       "0          0.56      9.4        5  \n",
       "1          0.68      9.8        5  \n",
       "2          0.65      9.8        5  \n",
       "3          0.58      9.8        6  \n",
       "4          0.56      9.4        5  \n",
       "...         ...      ...      ...  \n",
       "6492       0.50     11.2        6  \n",
       "6493       0.46      9.6        5  \n",
       "6494       0.46      9.4        6  \n",
       "6495       0.38     12.8        7  \n",
       "6496       0.32     11.8        6  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe will be analyzing the dataset by using Linear Regression with the pytorch module\\nSimple linear regression is an approach for predicting a response using a single \\nfeature. It is assumed that the two variables are linearly related.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We will be analyzing the dataset by using Linear Regression with the pytorch module\n",
    "Simple linear regression is an approach for predicting a response using a single \n",
    "feature. It is assumed that the two variables are linearly related.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol'],\n",
       " ['quality'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols = list(df.columns)[1:-1]\n",
    "output_cols = ['quality']\n",
    "input_cols, output_cols\n",
    "\n",
    "# X = df.iloc[:,:-1].values # features\n",
    "# Y = df.iloc[:,-1].values # dependent variable\n",
    "# X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_arrays(df):\n",
    "    df1 = df.copy(deep=True)\n",
    "    inputs_array = df1[input_cols].to_numpy()\n",
    "    targets_array = df1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 7.4 ,  0.7 ,  0.  , ...,  3.51,  0.56,  9.4 ],\n",
       "        [ 7.8 ,  0.88,  0.  , ...,  3.2 ,  0.68,  9.8 ],\n",
       "        [ 7.8 ,  0.76,  0.04, ...,  3.26,  0.65,  9.8 ],\n",
       "        ...,\n",
       "        [ 6.5 ,  0.24,  0.19, ...,  2.99,  0.46,  9.4 ],\n",
       "        [ 5.5 ,  0.29,  0.3 , ...,  3.34,  0.38, 12.8 ],\n",
       "        [ 6.  ,  0.21,  0.38, ...,  3.26,  0.32, 11.8 ]]),\n",
       " array([[5],\n",
       "        [5],\n",
       "        [5],\n",
       "        ...,\n",
       "        [6],\n",
       "        [7],\n",
       "        [6]], dtype=int64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = df_to_arrays(df)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.4000,  0.7000,  0.0000,  ...,  3.5100,  0.5600,  9.4000],\n",
       "         [ 7.8000,  0.8800,  0.0000,  ...,  3.2000,  0.6800,  9.8000],\n",
       "         [ 7.8000,  0.7600,  0.0400,  ...,  3.2600,  0.6500,  9.8000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " tensor([[5.],\n",
       "         [5.],\n",
       "         [5.],\n",
       "         ...,\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [6.]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs_array).type(torch.float)\n",
    "targets = torch.from_numpy(targets_array).type(torch.float)\n",
    "inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor and target tensor::   torch.Size([6497, 11]) torch.Size([6497, 1])\n",
      "datatype of input tensor and target tensor::   torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print('Shape of input tensor and target tensor::  ',inputs.shape, targets.shape)\n",
    "print('datatype of input tensor and target tensor::  ',inputs.dtype, targets.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x23ac7756ec8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(inputs, targets)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = random_split(dataset, [5200, 1297])\n",
    "batch_size = 200\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[ 6.3000,  0.3400,  0.2800,  ...,  3.2300,  0.4600,  9.5000],\n",
      "        [ 6.8000,  0.4100,  0.3100,  ...,  3.3800,  0.6400, 10.1000],\n",
      "        [ 6.7000,  0.1800,  0.3000,  ...,  3.2900,  0.5200, 10.0000],\n",
      "        ...,\n",
      "        [ 4.8000,  0.3300,  0.0000,  ...,  3.3500,  0.6100,  9.9000],\n",
      "        [ 6.0000,  0.5000,  0.0000,  ...,  3.3600,  0.4500,  9.5000],\n",
      "        [ 6.6000,  0.4000,  0.3000,  ...,  3.3600,  0.7300, 12.6000]])\n",
      "targets: tensor([[5.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [8.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [3.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [4.],\n",
      "        [6.],\n",
      "        [4.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [3.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [5.],\n",
      "        [7.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [7.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [8.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [3.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [8.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [8.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [7.],\n",
      "        [4.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [7.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [8.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [4.],\n",
      "        [7.],\n",
      "        [5.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [3.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [7.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [5.],\n",
      "        [8.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [5.],\n",
      "        [6.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print('inputs:', xb)\n",
    "    print('targets:', yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(xb.dtype, yb.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)\n",
    "input_size, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineQuality(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        out = self(inputs)\n",
    "        loss = F.l1_loss(out, targets)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        out = self(inputs)\n",
    "        loss = F.l1_loss(out, targets)\n",
    "        return {'val_loss': loss.detach()}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        if (epoch+1) % 100 == 0 or epoch == num_epochs-1:\n",
    "            print('Epoch [{}], val_loss: {:.4f}'.format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WineQuality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100], val_loss: 3.0075\n",
      "Epoch [200], val_loss: 2.8788\n",
      "Epoch [300], val_loss: 2.7561\n",
      "Epoch [400], val_loss: 2.6336\n",
      "Epoch [500], val_loss: 2.5185\n",
      "Epoch [600], val_loss: 2.4081\n",
      "Epoch [700], val_loss: 2.3009\n",
      "Epoch [800], val_loss: 2.1987\n",
      "Epoch [900], val_loss: 2.0994\n",
      "Epoch [1000], val_loss: 2.0046\n",
      "Epoch [1100], val_loss: 1.9131\n",
      "Epoch [1200], val_loss: 1.8265\n",
      "Epoch [1300], val_loss: 1.7434\n",
      "Epoch [1400], val_loss: 1.6665\n",
      "Epoch [1500], val_loss: 1.5912\n",
      "Epoch [1600], val_loss: 1.5191\n",
      "Epoch [1700], val_loss: 1.4508\n",
      "Epoch [1800], val_loss: 1.3858\n",
      "Epoch [1900], val_loss: 1.3238\n",
      "Epoch [2000], val_loss: 1.2650\n",
      "Epoch [2100], val_loss: 1.2092\n",
      "Epoch [2200], val_loss: 1.1559\n",
      "Epoch [2300], val_loss: 1.1068\n",
      "Epoch [2400], val_loss: 1.0602\n",
      "Epoch [2500], val_loss: 1.0159\n",
      "Epoch [2600], val_loss: 0.9741\n",
      "Epoch [2700], val_loss: 0.9343\n",
      "Epoch [2800], val_loss: 0.8974\n",
      "Epoch [2900], val_loss: 0.8631\n",
      "Epoch [3000], val_loss: 0.8312\n",
      "Epoch [3100], val_loss: 0.8021\n",
      "Epoch [3200], val_loss: 0.7757\n",
      "Epoch [3300], val_loss: 0.7513\n",
      "Epoch [3400], val_loss: 0.7293\n",
      "Epoch [3500], val_loss: 0.7102\n",
      "Epoch [3600], val_loss: 0.6934\n",
      "Epoch [3700], val_loss: 0.6795\n",
      "Epoch [3800], val_loss: 0.6676\n",
      "Epoch [3900], val_loss: 0.6571\n",
      "Epoch [4000], val_loss: 0.6485\n",
      "Epoch [4100], val_loss: 0.6413\n",
      "Epoch [4200], val_loss: 0.6351\n",
      "Epoch [4300], val_loss: 0.6301\n",
      "Epoch [4400], val_loss: 0.6254\n",
      "Epoch [4500], val_loss: 0.6222\n",
      "Epoch [4600], val_loss: 0.6193\n",
      "Epoch [4700], val_loss: 0.6171\n",
      "Epoch [4800], val_loss: 0.6153\n",
      "Epoch [4900], val_loss: 0.6138\n",
      "Epoch [5000], val_loss: 0.6125\n",
      "Epoch [5100], val_loss: 0.6117\n",
      "Epoch [5200], val_loss: 0.6109\n",
      "Epoch [5300], val_loss: 0.6103\n",
      "Epoch [5400], val_loss: 0.6098\n",
      "Epoch [5500], val_loss: 0.6096\n",
      "Epoch [5600], val_loss: 0.6093\n",
      "Epoch [5700], val_loss: 0.6090\n",
      "Epoch [5800], val_loss: 0.6088\n",
      "Epoch [5900], val_loss: 0.6087\n",
      "Epoch [6000], val_loss: 0.6085\n"
     ]
    }
   ],
   "source": [
    "epochs = 6000\n",
    "lr = 1e-6\n",
    "history5 = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 0.6085487604141235}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using linear regression with the pytorch module we are able to improve our score\n",
    "from 30% with linear regression with the sklearn module to 60%.\n",
    "It is still not great. Perhaps the data is not linearly related enough to make good\n",
    "predictions.\n",
    "'''\n",
    "\n",
    "result = evaluate(model, val_loader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('val_loss vs. No. of epochs');\n",
    "loss_mat = [res['val_loss'] for res in [result] + history5]\n",
    "plt.plot(loss_mat, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('val_loss')\n",
    "\n",
    "val_loss = loss_mat[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)\n",
    "    prediction = predictions[0].detach()\n",
    "    print('Input:', input)\n",
    "    print('Target:', target)\n",
    "    print('Prediction', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([7.9000e+00, 4.4000e-01, 2.6000e-01, 4.4500e+00, 3.3000e-02, 2.3000e+01,\n",
      "        1.0000e+02, 9.9117e-01, 3.1700e+00, 5.2000e-01, 1.2700e+01])\n",
      "Target: tensor([6.])\n",
      "Prediction tensor([6.8766])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[150]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
